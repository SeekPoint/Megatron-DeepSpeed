白强伟：【Megatron-DeepSpeed】张量并行工具代码mpu详解(四)：张量并行版Embedding层及交叉熵的实现及测试
白强伟：【Megatron-DeepSpeed】张量并行工具代码mpu详解(三)：张量并行层的实现及测试
白强伟：【Megatron-DeepSpeed】张量并行工具代码mpu详解(二)：Collective通信操作的封装mappings
白强伟：【Megatron-DeepSpeed】张量并行工具代码mpu详解(一)：并行环境初始化
https://zhuanlan.zhihu.com/p/619914112
上面的文章修改了部分代码，导致gpt2等无法运行！！！
=====


https://zhuanlan.zhihu.com/p/636334367
【DeepSpeed 教程翻译】二，Megatron-LM GPT2，Zero Redundancy Optimizer 和 ZeRO-Offload

https://zhuanlan.zhihu.com/p/579709267
从零开始 预训练 GPT

build和data主要参考这个
https://help.aliyun.com/zh/ecs/use-cases/use-the-megatron-deepspeed-training-gpt-2-and-generate-text


https://support.huaweicloud.com/usermanual-modelarts-lite/usermanual-modelarts-lite-0087.html
GPU Ant8裸金属服务器使用Megatron-Deepspeed训练GPT2并推理

https://66ring.github.io/2023/07/02/universe/ml/megatron_three_easy_pieces/
简单三步看清Megatron-LM的实现, Megatron源码解析


https://www.high-flyer.cn/blog/model_parallel-2/
模型并行 | 从Megatron谈Pipeline

https://www.high-flyer.cn/blog/model_parallel-1/inidex/
模型并行 | 大规模语言模型架构 Megatron
